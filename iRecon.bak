#!/bin/bash

# Author: Gzzcoo - epxanded by JackDaw

yellow="\e[33m"
blue="\e[34m"
gray="\e[90m"
end="\e[0m"
purple="\e[0;35m\033[1m"

if [ -z "$1" ]; then
    echo -e "\n${yellow}[!]${end} ${purple}Usage:${end} ${blue}$0 <IP>${end}"
    exit 1
fi

target="$1"

# Ensure we always use absolute paths (based on the current working directory)
BASE_PWD="$(pwd)"                     # the directory you ran the script from
OUTDIR="${BASE_PWD}/recon"            # absolute path to recon folder
mkdir -p "$OUTDIR"                    # create if missing
echo -e "${yellow}[*]${end} ${purple}Using output directory:${end} ${blue}$OUTDIR${end}"

figlet -f slant "iRecon" | lolcat

### run very fast nmap scan just to find open ports
echo -e "\n${yellow}[*]${end} ${purple}Scanning ports on${end} ${blue}$target${end}${purple}...${end}\n"
sudo /usr/bin/nmap -p- --open -sS --min-rate 1000 -n -Pn -vvv "$target" -oG $OUTDIR/allPorts 2>/dev/null | grep "Discovered open port"

### grab all those ports from the nmap scan and put them in a list
ip_address="$target"
ports=$(grep -oP '\d{1,5}/open' $OUTDIR/allPorts | cut -d '/' -f1 | xargs | tr ' ' ',')

echo -e "\n${yellow}[*]${end} ${purple}Extracting information...${end}\n" > extractPorts.tmp
echo -e "\t${yellow}[*]${end} ${purple}IP Address:${end} ${blue}$ip_address${end}" >> extractPorts.tmp
echo -e "\t${yellow}[*]${end} ${purple}Open ports:${end} ${blue}$ports${end}\n" >> extractPorts.tmp
echo "$ports" | tr -d '\n' | xclip -sel clip
echo -e "${yellow}[*]${end} ${purple}Ports copied to clipboard${end}" >> extractPorts.tmp
/usr/bin/batcat --style=plain --paging=never extractPorts.tmp
rm extractPorts.tmp

### run scan on detected ports
echo -e "\n${yellow}[*]${end} ${purple}Version and Service Scanning...${end}"
nmap -sCV -p"$ports" -n -Pn --max-retries 2 --host-timeout 30s "$ip_address" -A -oN "$OUTDIR/targeted" -oX "$OUTDIR/targetedXML" >/dev/null 2>&1

### http-detect
eval "$(./http-detect "$OUTDIR" "$ip_address")"
echo -e "${yellow}[*]${end} ${purple}HTTP candidates:${end} ${blue}${HTTP_CAND:-<none>}${end}"
echo -e "${yellow}[*]${end} ${purple}Verified HTTP ports:${end} ${blue}${HTTP_VERIFIED:-<none>}${end}"

# --- http-collect for verified HTTP ports (minimal & robust) ---
if [ -n "${HTTP_VERIFIED:-}" ]; then
  # HTTP_VERIFIED is a comma list like "80,8080"
  for p in $(echo "${HTTP_VERIFIED}" | tr ',' ' '); do
    # sanity: keep only digits
    p="${p//[^0-9]/}"
    [ -z "$p" ] && continue
    # call http-collect (no sudo); it expects OUTDIR IP PORT
    # ignore failures so iRecon continues
    ./http-collect "$OUTDIR" "$ip_address" "$p" >/dev/null 2>&1 || true
  done
fi
# --- end collection ---

# --- show emails we scraped from the HTTP bodies (if any) ---
emails_tmp="$OUTDIR/.emails.tmp"
: > "$emails_tmp"
if [ -n "${HTTP_VERIFIED:-}" ]; then
  for p in $(echo "${HTTP_VERIFIED}" | tr ',' ' '); do
    f="$OUTDIR/http/$p/emails.txt"
    [ -s "$f" ] && cat "$f" >> "$emails_tmp"
  done
fi
if [ -s "$emails_tmp" ]; then
  emails_sorted="$(sort -u "$emails_tmp")"
  echo -e "${yellow}[*]${end} ${purple}Emails found in page content:${end}"
  while IFS= read -r e; do
    echo -e "   ${blue}${e}${end}"
  done <<< "$emails_sorted"
fi
rm -f "$emails_tmp"
# --- end emails summary ---

# assume HTTP_CAND contains e.g. s3.thetoppers.htb and HTTP_VERIFIED contains ports
# prefer the hostname if present; else pass the IP
target_hint="${HTTP_CAND:-$ip_address}"
# produce candidate hosts silently (no heavy OSINT)
found_hosts="$(./passive-enrich "$OUTDIR" "$target_hint" --max 200)"
echo -e "${yellow}[*]${end} ${purple}Passive hosts found:${end}"
echo "$found_hosts" | sed '/^$/d' | while IFS= read -r h; do
  echo -e "   ${blue}$h${end}"
done
# optionally feed found_hosts into add-hosts (dry-run first)
./add-hosts "$OUTDIR" "$ip_address" "$(echo "$found_hosts" | paste -s -d, -)" --dry-run


# Preview what would be added (dry-run)
preview="$(./add-hosts "$OUTDIR" "$ip_address" "${HTTP_VERIFIED:-}" --dry-run 2>/dev/null || true)"
if [ -n "$preview" ]; then
  echo -e "${yellow}[*]${end} ${purple}Hosts that would be added to /etc/hosts:${end}"
  echo "$preview" | while IFS= read -r ln; do
    [ -z "$ln" ] && continue
    ip="${ln%% *}"; host="${ln#* }"
    echo -e "   ${blue}${ip}${end}  ${purple}${host}${end}"
  done
  # apply for real (single sudo prompt) â€” uncomment if you want automatic apply:
  # added="$(sudo bash ./add-hosts "$OUTDIR" "$ip_address" "${HTTP_VERIFIED:-}")"
  # echo "$added"
else
  echo -e "${yellow}[*]${end} ${purple}No new /etc/hosts entries needed.${end}"
fi

### generate HTML report
echo -e "\n${yellow}[*]${end} ${purple}Generating HTML Report and opening with the browser...${end}"
# generate HTML report from Nmap XML using the nmap stylesheet (safe order & checks)
NMAP_XSL="/usr/share/nmap/nmap.xsl"
if [ ! -f "$NMAP_XSL" ]; then
  NMAP_XSL="$(find /usr -name nmap.xsl 2>/dev/null | head -n1 || true)"
fi

if [ -s $OUTDIR/targetedXML ]; then
  if [ -n "$NMAP_XSL" ] && [ -f "$NMAP_XSL" ]; then
    xsltproc -o $OUTDIR/index.html "$NMAP_XSL" $OUTDIR/targetedXML || echo "[!] xsltproc failed"
  else
    echo "[!] nmap.xsl stylesheet not found; cannot generate HTML"
  fi
else
  echo "[!] targetedXML missing or empty; skipping HTML generation"
fi


(
    python3 -m http.server 6969 -d $OUTDIR &
    server_pid=$!
    sleep 1
    /usr/bin/firefox http://127.0.0.1:6969/index.html &
    sleep 6
    kill "$server_pid" &>/dev/null
) &>/dev/null
